{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ebf29e-fe09-438c-b611-935ce387fe52",
   "metadata": {},
   "source": [
    "# Parallel loops through numpy arrays\n",
    "We look at speeding up loops through numpy arrays. In this example we have to call a third-party library in each iteration and this third-party library will only accept a subset of our total array. As we are calling a third-party library we can't apply tricks like JIT compilation.\n",
    "\n",
    "The scenario here is that we have a 3-dimensional array with dimensions (x,y,time). We will imagine that this is a time series of 2-dimensional maps of ocean salinity. Our third-party library is the seawater library. We assume that the seawater library only accepts 2-dimensional inputs so we need to loop through the time dimension and call this library on each iteration. \n",
    "\n",
    "# Libraries\n",
    "\n",
    "#### In this example we will use the built-in [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module, [Joblib](https://joblib.readthedocs.io/en/latest/) and [dask](https://docs.dask.org/en/stable/) libraries.  In the case of Dask we are using the `dask delayed` API for parallelising the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888b387e-39d7-4132-86b5-d8a53a89580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May need to install gsw seawater library here\n",
    "# !conda install --yes -c conda-forge gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4ae17f-fa1a-4670-9a03-71183b9579e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor,ThreadPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel,delayed\n",
    "import dask\n",
    "\n",
    "import gsw\n",
    "# Import the gswImport function from a script so the parallel processing will run it\n",
    "import gswImport\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ff138f-7efc-45bd-b29b-edd8ff46ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a956b9c-6a82-48d3-8b65-0204f7305d9f",
   "metadata": {},
   "source": [
    "# Generate data\n",
    "We generate the inputs we need for the seawater library. We add arguments to allow us to specify the size of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a997fbf8-d1f3-42e6-a3d8-ad51a1da6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(xyLength:int,timesteps:int):\n",
    "    SalinityTimeseries = 35 + np.random.standard_normal(size=(xyLength,xyLength,timesteps))\n",
    "    assert SalinityTimeseries.shape == (xyLength,xyLength,timesteps)\n",
    "    p = 0\n",
    "    lon = np.tile(np.linspace(0,100,xyLength)[:,np.newaxis],xyLength)\n",
    "    assert lon.shape == (xyLength,xyLength)\n",
    "    lat = np.tile(np.linspace(-30,30,xyLength)[:,np.newaxis],xyLength)\n",
    "    assert lat.shape == (xyLength,xyLength)\n",
    "    return SalinityTimeseries,p,lon,lat\n",
    "\n",
    "SalinityTimeseries,p,lon,lat = generateData(xyLength=3,timesteps=5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b9265-0b8b-45e2-91ae-e121272c9b9d",
   "metadata": {},
   "source": [
    "#### We define the function that we are going to call in each iteration: `getAbsoluteSalinity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7576fb64-c8d4-4e7b-86b7-3eab94713360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAbsoluteSalinity(SalinitySnapshot:np.ndarray,p:int,lon:np.ndarray,lat:np.ndarray,index=None):\n",
    "    return (gsw.SA_from_SP(SalinitySnapshot,p,lon,lat),index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225718b0-aef7-4f09-81d6-41a47a217e98",
   "metadata": {},
   "source": [
    "#### Serial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b0004a8-3687-4389-bc62-ca056d9afa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequentialProcessing(SalinityTimeseries:np.ndarray,p:int,lon:np.ndarray,lat:np.ndarray,):\n",
    "    return np.stack(\n",
    "        [getAbsoluteSalinity(SalinityTimeseries[:,:,timestep], p, lon, lat)[0] for timestep in range(SPTimeseries.shape[2])],\n",
    "        axis=2)\n",
    "\n",
    "outputSeq = sequentialProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e3347-e9d0-4d0f-bce9-8f3b30e083e8",
   "metadata": {},
   "source": [
    "# Concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f08bfe0-f707-4b28-9668-8aae5e3db028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortResultsToArray(results:list):\n",
    "    # Make sure the results are sorted correctly by timestamp\n",
    "    results = sorted(results,key=lambda x:x[1])\n",
    "    # Drop the timestamp index from each element\n",
    "    results = [el[0] for el in results]\n",
    "    # Turn the list of arrays back into a single array\n",
    "    results = np.stack(results,axis=2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b73aa9-d41f-489c-9d30-ff8d664116cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concurrentProcessing(SalinityTimeseries:np.ndarray,p:int,lon:np.ndarray,lat:np.ndarray,backend = \"multiprocessing\"):\n",
    "    results = []\n",
    "    if backend == \"multiprocessing\":\n",
    "        executor = ProcessPoolExecutor()\n",
    "    else:\n",
    "        executor = ThreadPoolExecutor()\n",
    "    with executor as pool:\n",
    "        futr_results = [\n",
    "            pool.submit(\n",
    "                gswImport.getAbsoluteSalinity,SalinityTimeseries[:,:,timestep],p,lon,lat,timestep) for timestep in range(SalinityTimeseries.shape[2]\n",
    "                                                                                               )\n",
    "        ]\n",
    "        for future in futr_results: \n",
    "            results.append(future.result())\n",
    "    results = sortResultsToArray(results=results)\n",
    "    return results\n",
    "# Check the function runs\n",
    "outputConcurrent = concurrentProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,backend = \"multiprocessing\")\n",
    "# Check the output matches the serial run\n",
    "np.testing.assert_array_equal(outputSeq,outputConcurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df9d06-cf08-4d1f-aa88-f902cf003ac3",
   "metadata": {},
   "source": [
    "# Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38abe00c-a121-4ac8-b29b-3fe3131a12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joblibProcessing(SalinityTimeseries:np.ndarray,p:int,lon:np.ndarray,lat:np.ndarray,backend = \"threading\",n_jobs:int=2):\n",
    "    results = Parallel(n_jobs=n_jobs, backend=backend)(delayed(getAbsoluteSalinity)(SalinityTimeseries[:,:,timestep], p, lon, lat,timestep) for timestep in range(SalinityTimeseries.shape[2]))\n",
    "    results = sortResultsToArray(results=results)\n",
    "    return results\n",
    "\n",
    "outputParallel = joblibProcessing(SPTimeseries=SPTimeseries,p=p,lon=lon,lat=lat,n_jobs=1)\n",
    "np.testing.assert_array_equal(outputSeq,outputParallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3642f7-cb77-4d9a-a63e-a237afe0e8be",
   "metadata": {},
   "source": [
    "# Dask Delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c0ebe09-bba3-411f-ba75-cbb7c1bfe928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daskDelayedProcessing(SalinityTimeseries:np.ndarray,p:int,lon:np.ndarray,lat:np.ndarray):\n",
    "    results = []\n",
    "    for timestep in range(SalinityTimeseries.shape[2]):\n",
    "        results.append(dask.delayed(\n",
    "            getAbsoluteSalinity)(SalinityTimeseries[:,:,timestep], p, lon, lat,timestep)\n",
    "                      )\n",
    "    results = dask.compute(*results)\n",
    "    results = sortResultsToArray(results=results)\n",
    "    return results\n",
    "\n",
    "outputDask = daskDelayedProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat)\n",
    "np.testing.assert_array_equal(outputParallel,outputDask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56464ee5-4ba1-4393-b300-ca610545a488",
   "metadata": {},
   "source": [
    "#### Generate some larger data for timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ff0f93-2372-46a1-b432-d32893420178",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyLength = 1000\n",
    "timesteps = 100\n",
    "SPTimeseries,p,lon,lat = generateData(xyLength=xyLength,timesteps=timesteps)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02205a2c-5e84-418a-96c4-1cd1e2ec634c",
   "metadata": {},
   "source": [
    "#### Do timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536942f2-421c-4a95-a2be-55645c7f89a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Serial processing**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 s ± 374 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Concurent.futures multiprocessing**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5 s ± 800 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Concurent.futures threading**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 s ± 193 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Joblib processing 2 jobs**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.46 s ± 300 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Joblib processing 4 jobs**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.77 s ± 19.6 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Joblib processing 8 jobs**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.43 s ± 35 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Dask delayed processing**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.57 s ± 66.1 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "printmd(\"**Serial processing**\")\n",
    "%timeit -n 1 -r 5 sequentialProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat)\n",
    "printmd(\"**Concurent.futures multiprocessing**\")\n",
    "%timeit -n 1 -r 5 concurrentProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,backend = \"multiprocessing\")\n",
    "printmd(\"**Concurent.futures threading**\")\n",
    "%timeit -n 1 -r 5 concurrentProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,backend = \"threading\")\n",
    "printmd(\"**Joblib processing 2 jobs**\")\n",
    "%timeit -n 1 -r 5 joblibProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,n_jobs=2)\n",
    "printmd(\"**Joblib processing 4 jobs**\")\n",
    "%timeit -n 1 -r 5 joblibProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,n_jobs=4)\n",
    "printmd(\"**Joblib processing 8 jobs**\")\n",
    "%timeit -n 1 -r 5 joblibProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat,n_jobs=8)\n",
    "printmd(\"**Dask delayed processing**\")\n",
    "%timeit  -n 1 -r 5 daskDelayedProcessing(SalinityTimeseries=SalinityTimeseries,p=p,lon=lon,lat=lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce426364-4c8b-4871-8862-c44b888ee50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
